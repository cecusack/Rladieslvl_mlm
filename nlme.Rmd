---
title: "nlme_rladies"
author: "CCusack"
date: "2023-07-23"
output: 
  html_document:
    toc: true
    toc_depth: 6
    toc_float: true
    number_sections: true
    code_folding: hide
    theme: cosmo
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

- data from Aaron Fisher https://osf.io/nt37e/

# libs dat

```{r message=FALSE, warning=FALSE}
#### my almost always packages ####
if (!require("psych")) {install.packages("psych"); require("psych")}
if (!require("tidyverse")) {install.packages("tidyverse"); require("tidyverse")}

#### data wrangling packages ####
if (!require("purrr")) {install.packages("purrr"); require("purrr")}
if (!require("sjmisc")) {install.packages("sjmisc"); require("sjmisc")}
if (!require("DataCombine")) {install.packages("DataCombine"); require("DataCombine")}
if (!require("data.table")) {install.packages("data.table"); require("data.table")}
if (!require("plyr")) {install.packages("plyr"); require("plyr")} 

#### mlm packages ####
if (!require("nlme")) {install.packages("nlme"); require("nlme")} # mixed effects models
if (!require("psychometric")) {install.packages("psychometric"); require("psychometric")} # iccs
if (!require("r2mlm")) {install.packages("r2mlm"); require("r2mlm")} # pseudo-r squared  

dat <- read.csv("mlm_dat.csv")
dim(dat) # 10217 x 32
length(unique(dat$ID)) # 79

```

# data management

## night lags

Here, I:    
1. **add an empty row** after the last beep of the day to account for night lags    
2. **fill in the ID and date** from the row above    
3. **remove the last empty row** for each participant (e.g., remove the empty row btween ID_001 and ID_003)   
4. **renumber beeps**

```{r}
dat <- dat %>% 
  group_split(ID, dayvar) %>% 
  map_dfr(~ add_row(.x, .after = Inf))

dat <- dat %>% tidyr::fill(ID, date)
dat <- dat %>% group_by(ID) %>% slice(-n())

dat <- dat %>% group_by(ID) %>% 
  dplyr::mutate(beepconsec = seq(1:n())) %>% 
  ungroup()
```

## btwn and within

In these code chunks, I create "trait" like variables for the mean. Then, I center them. I create "state" like variables that subtract their trait-like variable from their momentary value. Then, I lag variables (shit down one row.)

### trait vars
```{r}
dat_means <- dat %>% group_by(ID) %>%
summarise_at(vars(energetic:avoid_people), mean, na.rm=TRUE)

colnames(dat_means)[c(2:ncol(dat_means))] <- paste(colnames(dat_means)[c(2:ncol(dat_means))],"trait",sep="_")

dat <- merge(dat, dat_means, by="ID")
```

### center trait vars
```{r}
dat <- dat %>%
  mutate_at(vars(ends_with("trait")),  list(mod = ~ scale(., center=TRUE, scale=FALSE))) %>%
  rename_at(vars(ends_with("_mod")), list(~ paste(gsub("_mod", "_cent", .))))
```

### create state vars
```{r}
# there's definitely a more elegant solution, but here we are
xx = colnames(dat[c(which(colnames(dat)=="energetic"):which(colnames(dat)=="avoid_people"))])
xx <- paste(xx, "state", sep = "_")
dat[xx] <- NA

dat <- dat %>% 
  mutate(energetic_state = energetic - energetic_trait) %>% 
  mutate(enthusiastic_state = enthusiastic - enthusiastic_trait) %>% 
  mutate(content_state = content - content_trait) %>% 
  mutate(irritable_state = irritable - irritable_trait) %>% 
  mutate(restless_state = restless - restless_trait) %>% 
  mutate(worried_state = worried - worried_trait) %>% 
  mutate(guilty_state = guilty - guilty_trait) %>% 
  mutate(afraid_state = afraid - afraid_trait) %>% 
  mutate(anhedonia_state = anhedonia - anhedonia_trait) %>% 
  mutate(angry_state = angry - angry_trait) %>% 
  mutate(hopeless_state = hopeless - hopeless_trait) %>% 
  mutate(down_state = down - down_trait) %>% 
  mutate(positive_state = positive - positive_trait) %>% 
  mutate(fatigue_state = fatigue - fatigue_trait) %>% 
  mutate(tension_state = tension - tension_trait) %>% 
  mutate(concentrate_state = concentrate - concentrate_trait) %>% 
  mutate(accepted_state = accepted - accepted_trait) %>% 
  mutate(threatened_state = threatened - threatened_trait) %>% 
  mutate(ruminate_state = ruminate - ruminate_trait) %>% 
  mutate(avoid_act_state = avoid_act - avoid_act_trait) %>% 
  mutate(reassure_state = reassure - reassure_trait) %>% 
  mutate(procrast_state = procrast - procrast_trait) %>% 
  mutate(hours_state = hours - hours_trait) %>% 
  mutate(difficult_state = difficult - difficult_trait) %>% 
  mutate(unsatisfy_state = unsatisfy - unsatisfy_trait) %>% 
  mutate(avoid_people_state = avoid_people - avoid_people_trait) 
```

### lag
```{r}
namesoriginal <- names(dat[c(which(colnames(dat)=="energetic"):which(colnames(dat)=="avoid_people"))]) # save original names in a vector
nameslag <- paste(names(dat[c(which(colnames(dat)=="energetic"):which(colnames(dat)=="avoid_people"))]), "_lag", sep="") # save new names in a vector

list <- split(dat, dat$ID) # split df by id

list  <- list %>%  # shift all list elements with columns in name original
  map(~shift(.x[namesoriginal],  n = -1, fill=NA, type="lead"))

for(i in seq_along(list)){ # make each list element a dataframe
  list[[i]] <- do.call("cbind", list[[i]])
}

lagdf <- ldply(list, data.frame) # list as dataframe
names(lagdf) <- c("ID", nameslag) # rename vars
lagdf <- lagdf[-1] # remove ID col

dat <- cbind(dat, lagdf) # add lagged vars to dataframe

# clean up environment
rm(list, lagdf, namesoriginal, nameslag, i)

# save df
write.csv(dat, "mlm_dat_processed.csv", row.names = FALSE)
```

# if you start here with preproccesed dat
```{r}
rm(list=ls())
#### my almost always packages ####
if (!require("psych")) {install.packages("psych"); require("psych")}
if (!require("tidyverse")) {install.packages("tidyverse"); require("tidyverse")}

#### data wrangling packages ####
if (!require("purrr")) {install.packages("purrr"); require("purrr")}
if (!require("sjmisc")) {install.packages("sjmisc"); require("sjmisc")}
if (!require("DataCombine")) {install.packages("DataCombine"); require("DataCombine")}
if (!require("data.table")) {install.packages("data.table"); require("data.table")}
if (!require("plyr")) {install.packages("plyr"); require("plyr")} 

#### mlm packages ####
if (!require("nlme")) {install.packages("nlme"); require("nlme")} # mixed effects models
if (!require("psychometric")) {install.packages("psychometric"); require("psychometric")} # iccs
if (!require("r2mlm")) {install.packages("r2mlm"); require("r2mlm")} # pseudo-r squared  
if (!require("insight")) {install.packages("insight"); require("insight")}
dat <- read.csv("mlm_dat_processed.csv")
```

# brief data overview

We have 79 participants who completed an average of 129 surveys (*SD* = 16.67, Min = 103, Max = 213) across 55 days.

```{r}
head(dat)
# note data are in long form. Each observation is it's own row. This form contrasts wide-format where each participant is it's own row and may have multiple time points as columns
```

Summary stats for study. For EMA studies, want to report participants and how many observations are within participants.

```{r}
# number of unique participants
length(unique(dat$ID)) # 79

dat %>% 
  filter(!is.na(time)) %>%  # exclude time lag rows
  group_by(ID) %>% # group by participant
  tally() %>% # survey count by participant
  summarise(meanobs = mean(n), median(n), sdobs=sd(n), minobs=min(n), maxobs=max(n)) 

# Participants completed an average of 129 surveys (SD = 16.67). Minimum number of surveys = 103, maximum surveys = 213.

describe(dat[c(which(colnames(dat)=="dayvar"), which(colnames(dat)=="beepvar"))]) # maximum of 55 days, max beep var is 5 but I know I added an empty row between last beep and first beep so actually 4 pings per day
```

## visualize variables

before you model, it's good to have a sense of the shape of your data. I visualize histogram below. skimr::skimr also is good/easy for this purpose.
```{r}
dens_fun <- function(var, name) {
  ggplot(dat, aes(x = var)) +
    geom_histogram() +
    theme_classic() +
    labs(x = name,
         title = name)
}

dat %>% 
  dplyr::select(avoid_people, worried_trait, worried_state) %>% 
  map2(.y = names(.),
       ~ dens_fun(.x, .y)
  )

library(skimr)
skim(dat[c(which(colnames(dat)=="avoid_people"), which(colnames(dat)=="worried_trait"), which(colnames(dat)=="worried_state"))])
```


# ICC
```{r}
#### ICC ####
ICC1.lme(avoid_people_lag, ID, data=dat) # 0.49 variance is at the btwn person level
```

# Random-intercept only

```{r}
avoid_RE = lme(avoid_people_lag ~ 1,
            random =~ 1|ID,
            data=dat,
            method="ML", 
            na.action = na.exclude)

summary(avoid_RE)
# average avoidance score is 27.19
# within-person effect is 19.03 (how much individuals vary from grand mean)
# number of groups and observations, does it match what you expect?
```

### RE with AR(1) correlation structure
```{r}
avoid_RE1 = lme(avoid_people_lag ~ 1,
            random =~ 1|ID,
            data=dat,
            correlation = corCAR1(form=~beepconsec), 
            method="ML", 
            na.action = na.exclude)
summary(avoid_RE1)
# the average avoidance score is 27.18 with an SD in individual scores being 2.15
# random effect (within person diff) = 18.97 (how much individuals vary from fixed effect); 
# between person diff 19.57 is how much individuals vary from each other
intervals(avoid_RE1)
# if CI contains zero, random effects null

anova(avoid_RE, avoid_RE1) # here we see adding the AR1 correlation structure results in a better model fit
```

# add fixed effects

add in worry as both between-person (`worried_trait`) and within-person (`worrired_state`) predictor

Is avoiding people a function of general and momentary worry?

```{r}
avoid_anx1 = lme(avoid_people_lag ~ worried_trait + worried_state,
            random =~ 1|ID,
            data=dat,
            correlation= corCAR1(form=~beepconsec),
            method="ML", # maximum likelihood estimation
            na.action = "na.omit")
summary(avoid_anx1)
# fixed effects: the between person effect is much stronger than within person effect. 
# For each unit increase in momentary worry, avoiding people increases by 0.06. For each unit increase in avg worry, avoiding people increases by 0.55.
```

## confidence intervals fixed effects
```{r}
intervals(avoid_anx1)
```

```{r}
# coef(avoid_anx1) # here we can see our fixed effects are constant and our intercepts vary by participant
```

## pseudo- r squared
```{r}
r2mlm(avoid_anx1, bargraph = TRUE)
# fvm represents the total outcome variance explained by predictors through fixed slopes and random slope variation/covariation and between-person random intercept variation (e.g., total R2 measure; R2total) 0.4903065
# 2) v represents the proportion of outcome variance explained by predictors via random slope variation/covariation (e.g., within-person R2 measure; R2within); 0.00 
# 3) f2 represents the proportion outcome variance explained by between-person variables fixed slopes (e.g., between-person R2 measure; R2between) .25
```

## assumptions
```{r}
qqnorm(residuals(avoid_anx1)) # normality of resid
qqnorm(avoid_anx1, ~ranef(., level=1)) # normality of random effects
plot(avoid_anx1) 
```

# add random effect for within-person associations

Let momentary worry vary across persons

```{r}
avoid_anx2 = lme(avoid_people_lag ~ worried_trait + worried_state,
            random =~ 1 + worried_state|ID,
            data=dat,
            correlation= corCAR1(form=~beepconsec),
            method="ML", 
            na.action = "na.omit")

summary(avoid_anx2)
# positive slope. pos correlation = .19 correlation btwn ind diff and the within person coupling. People w/ more people avoidance have a stronger association w/ avoidance and momentary worry
```

## CIs
```{r}
intervals(avoid_anx2)
get_variance(avoid_anx2)
# var fixed 179.2374 (variance attributed to FEs)
# var intercept 176.0984 (between subject variance)
# var random (mean variance of REs)
# var resid 368.2388 (residual variance)
# random slope variance .012
# cor.slope_intercept 0.19 (relation btwn random slope and intercept)
VarCorr(avoid_anx2) 
# variance/sd estimates for random effects. corr is the relation among REs within the same level of grouping
```

# compare mods
```{r}
anova.lme(avoid_anx1, avoid_anx2) # avoid_anx2 has lower AIC and BIC values. model 2 is a better fit than model 1, we should let the random slopes vary
```

## pseudo-rsquare
```{r}
r2mlm(avoid_anx2, bargraph = TRUE) 
# fvm = 0.493176037
# v = 0.01
# f2 = 0.25

```

## assumptions
```{r}
qqnorm(residuals(avoid_anx2))
qqnorm(avoid_anx2, ~ranef(., level=1))
plot(avoid_anx2)
```

# plots

## avoid people - worry trait
```{r warning=FALSE}
# plotting avoid people by trait like worry
dat %>% 
  filter(beepconsec<200) %>% 
  ggplot(aes(worried_trait, avoid_people)) +
  geom_smooth(method='lm', se=TRUE) + 
  # geom_point(color='black',size=.1) +
  labs(x = "Trait Worry", y = "Avoid People (0-100)") +
  theme_classic() +
  coord_cartesian(ylim=c(0,100))
```

## momentary worry and avoid
```{r}
dat %>%
  filter(beepconsec<200) %>% 
  ggplot(aes(x=worried_state, y=avoid_people, group=ID, color=ID))+
  geom_smooth(method = "lm", se=FALSE, size=.5)+ # toggle se TRUE
  labs(x="Momentary Worry", y="Avoid People (0-100)") +
  theme_classic() +
  theme(legend.position = "none") +
  coord_cartesian(ylim=c(0,100))
```

## momentary worry avoid facet
```{r warning=FALSE}
# facet
dat %>%
  filter(beepconsec<200) %>% 
  ggplot(aes(x=worried_state, y=avoid_people, group=ID, color=ID))+
  geom_smooth(method = "loess", se=FALSE, size=.5)+
  labs(x="Momentary Worry", y="Avoid People (0-100)") +
  theme_classic() +
  theme(legend.position = "none") +
  coord_cartesian(ylim=c(0,100)) +
  facet_wrap(~ID)  # generally people stay high or stay low
```

